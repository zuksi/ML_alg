{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Обучить любую модель классификации на датасете IRIS до применения PCA (d = 2) и после него. Сравнить качество классификации по отложенной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я решила использовать решающее дерево. Использую свой код с остановкой в случае, когда все объекты в листе относятся к одному классу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
    "        self.t = t  # значение порога\n",
    "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
    "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data # значения признаков\n",
    "        self.labels = labels  # y_true\n",
    "        self.prediction = self.predict()  # y_pred\n",
    "        \n",
    "    def predict(self):\n",
    "        # подсчет количества объектов разных классов\n",
    "        classes = {}  # сформируем словарь \"класс: количество объектов\"\n",
    "        for label in self.labels:\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += 1\n",
    "        #  найдем класс, количество объектов которого будет максимальным в этом листе и вернем его   \n",
    "        prediction = max(classes, key=classes.get)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(labels):\n",
    "    #  подсчет количества объектов разных классов\n",
    "    classes = {}\n",
    "    for label in labels:\n",
    "        if label not in classes:\n",
    "            classes[label] = 0\n",
    "        classes[label] += 1\n",
    "    \n",
    "    #  расчет критерия\n",
    "    impurity = 1     # \"impurity\" - \"нечистота\", степень неопределенности\n",
    "    for label in classes:\n",
    "        p = classes[label] / len(labels) # долю объектов класса в листе\n",
    "        impurity -= p ** 2 # Критерий Джини\n",
    "        \n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality(left_labels, right_labels, current_gini):\n",
    "\n",
    "    # доля выборки, ушедшей в левое поддерево\n",
    "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0]) # для правого (1-p)\n",
    "    \n",
    "    return current_gini - p * gini(left_labels) - (1 - p) * gini(right_labels) # Функционал качества/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, labels, index, t):\n",
    "    \n",
    "    left = np.where(data[:, index] <= t)\n",
    "    right = np.where(data[:, index] > t)\n",
    "        \n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "        \n",
    "    return true_data, false_data, true_labels, false_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(data, labels):\n",
    "\n",
    "    current_gini = gini(labels) \n",
    "\n",
    "    best_quality = 0\n",
    "    best_t = None \n",
    "    best_index = None \n",
    "    \n",
    "    n_features = data.shape[1] \n",
    "    \n",
    "    for index in range(n_features): \n",
    "        t_values = [row[index] for row in data] \n",
    "        \n",
    "        for t in t_values: \n",
    "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t) \n",
    "            \n",
    "            current_quality = quality(true_labels, false_labels, current_gini)\n",
    "            \n",
    "            if current_quality > best_quality:\n",
    "                best_quality, best_t, best_index = current_quality, t, index\n",
    "\n",
    "    return best_quality, best_t, best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(data, labels):\n",
    "\n",
    "    quality, t, index = find_best_split(data, labels) \n",
    "\n",
    "    if len(set(labels)) == 1: # если все значения относятся к одному классу, возвращаем лист\n",
    "        \n",
    "        return Leaf(data, labels) \n",
    "    \n",
    "   \n",
    "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "\n",
    "    \n",
    "    true_branch = build_tree(true_data, true_labels)\n",
    "    false_branch = build_tree(false_data, false_labels)\n",
    "\n",
    "    \n",
    "    return Node(index, t, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_object(obj, node):\n",
    "\n",
    "    #  Останавливаем рекурсию, если достигли листа\n",
    "    if isinstance(node, Leaf): # проверка текущий узел это лист?\n",
    "        answer = node.prediction # считаем прогноз для листа\n",
    "        return answer\n",
    "\n",
    "    if obj[node.index] <= node.t: # если значение признака меньше порога t\n",
    "        return classify_object(obj, node.true_branch) # рекурсия: отправляем объект в true-ветку\n",
    "    else:\n",
    "        return classify_object(obj, node.false_branch) # рекурсия: отправляем объект в false-ветку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, tree):\n",
    "    \n",
    "    classes = []\n",
    "    \n",
    "    for obj in data:\n",
    "        prediction = classify_object(obj, tree) # определяем ветки для объектов\n",
    "        classes.append(prediction)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree = build_tree(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_answers = predict(X_train, my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = predict(X_test, my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy = accuracy_metric(y_train, train_answers)\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.55555555555556"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = accuracy_metric(y_test, answers)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для начала отмасштабируем выборку\n",
    "X_ = X.astype(float)\n",
    "\n",
    "rows, cols = X_.shape\n",
    "\n",
    "# центрирование - вычитание из каждого значения среднего по строке\n",
    "means = X_.mean(0)\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        X_[i, j] -= means[j]\n",
    "\n",
    "# деление каждого значения на стандартное отклонение\n",
    "std = np.std(X_, axis=0)\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        X_[j][i] /= std[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собственные значения в порядке убывания:\n",
      "(437.7746724797993, array([ 0.52106591, -0.26934744,  0.5804131 ,  0.56485654]))\n",
      "(137.10457072021043, array([-0.37741762, -0.92329566, -0.02449161, -0.06694199]))\n",
      "(22.013531335697234, array([-0.71956635,  0.24438178,  0.14212637,  0.63427274]))\n",
      "(3.1072254642928705, array([ 0.26128628, -0.12350962, -0.80144925,  0.52359713]))\n"
     ]
    }
   ],
   "source": [
    "covariance_matrix = X_.T.dot(X_)\n",
    "\n",
    "eig_values, eig_vectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "# сформируем список кортежей (собственное значение, собственный вектор)\n",
    "eig_pairs = [(np.abs(eig_values[i]), eig_vectors[:, i]) for i in range(len(eig_values))]\n",
    "\n",
    "# и отсортируем список по убыванию собственных значений\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print('Собственные значения в порядке убывания:')\n",
    "for i in eig_pairs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля дисперсии, описываемая каждой из компонент \n",
      "[72.96244541329989, 22.850761786701742, 3.668921889282873, 0.5178709107154785]\n",
      "Кумулятивная доля дисперсии по компонентам \n",
      "[ 72.96244541  95.8132072   99.48212909 100.        ]\n"
     ]
    }
   ],
   "source": [
    "eig_sum = sum(eig_values)\n",
    "var_exp = [(i / eig_sum) * 100 for i in sorted(eig_values, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print(f'Доля дисперсии, описываемая каждой из компонент \\n{var_exp}')\n",
    "\n",
    "# а теперя оценим кумулятивную (то есть накапливаемую) дисперсию при учитывании каждой из компонент\n",
    "print(f'Кумулятивная доля дисперсии по компонентам \\n{cum_var_exp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Матрица весов W:\n",
      " [[ 0.52106591 -0.37741762]\n",
      " [-0.26934744 -0.92329566]\n",
      " [ 0.5804131  -0.02449161]\n",
      " [ 0.56485654 -0.06694199]]\n"
     ]
    }
   ],
   "source": [
    "W = np.hstack((eig_pairs[0][1].reshape(4,1), eig_pairs[1][1].reshape(4,1)))\n",
    "\n",
    "print(f'Матрица весов W:\\n', W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = X_.dot(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.26470281, -0.4800266 ],\n",
       "       [-2.08096115,  0.67413356],\n",
       "       [-2.36422905,  0.34190802],\n",
       "       [-2.29938422,  0.59739451],\n",
       "       [-2.38984217, -0.64683538],\n",
       "       [-2.07563095, -1.48917752],\n",
       "       [-2.44402884, -0.0476442 ],\n",
       "       [-2.23284716, -0.22314807],\n",
       "       [-2.33464048,  1.11532768],\n",
       "       [-2.18432817,  0.46901356]])"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train, Z_test, y_train, y_test = model_selection.train_test_split(Z, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_tree = build_tree(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_answers_pca = predict(Z_train, pca_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_pca = predict(Z_test, pca_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy_pca = accuracy_metric(y_train, train_answers_pca)\n",
    "train_accuracy_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.55555555555556"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy_pca = accuracy_metric(y_test, answers_pca)\n",
    "test_accuracy_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае, после применения PCA качество классификации не изменилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2*. Написать свою реализацию метода главных компонент с помощью сингулярного разложения с использованием функции numpy.linalg.svd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "V  = np.linalg.svd(X_)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52106591, -0.26934744,  0.5804131 ,  0.56485654],\n",
       "       [-0.37741762, -0.92329566, -0.02449161, -0.06694199],\n",
       "       [ 0.71956635, -0.24438178, -0.14212637, -0.63427274],\n",
       "       [ 0.26128628, -0.12350962, -0.80144925,  0.52359713]])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку векторы отсортированы в порядке убывания собственных значений, выбираем первые два."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52106591, -0.37741762],\n",
       "       [-0.26934744, -0.92329566],\n",
       "       [ 0.5804131 , -0.02449161],\n",
       "       [ 0.56485654, -0.06694199]])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_svd = np.hstack((V[0].reshape(4,1), V[1].reshape(4,1)))\n",
    "W_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_svd = X_.dot(W_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.26470281, -0.4800266 ],\n",
       "       [-2.08096115,  0.67413356],\n",
       "       [-2.36422905,  0.34190802],\n",
       "       [-2.29938422,  0.59739451],\n",
       "       [-2.38984217, -0.64683538],\n",
       "       [-2.07563095, -1.48917752],\n",
       "       [-2.44402884, -0.0476442 ],\n",
       "       [-2.23284716, -0.22314807],\n",
       "       [-2.33464048,  1.11532768],\n",
       "       [-2.18432817,  0.46901356]])"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_svd[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components = 2)\n",
    "SVDreduced = svd.fit_transform(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.26470281,  0.4800266 ],\n",
       "       [-2.08096115, -0.67413356],\n",
       "       [-2.36422905, -0.34190802],\n",
       "       [-2.29938422, -0.59739451],\n",
       "       [-2.38984217,  0.64683538],\n",
       "       [-2.07563095,  1.48917752],\n",
       "       [-2.44402884,  0.0476442 ],\n",
       "       [-2.23284716,  0.22314807],\n",
       "       [-2.33464048, -1.11532768],\n",
       "       [-2.18432817, -0.46901356]])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVDreduced[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
